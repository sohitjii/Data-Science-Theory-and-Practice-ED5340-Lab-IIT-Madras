{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c261393",
   "metadata": {},
   "source": [
    "# Name - SOHIT PATHAK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf10d3a",
   "metadata": {},
   "source": [
    "# Roll No: MA22M019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973656c0",
   "metadata": {},
   "source": [
    "Neural network with BP and FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94a4f4",
   "metadata": {},
   "source": [
    "Implement the two layer network for m-samples, n-features as we discussed in class (both FP and BP) and for N layers in the hidden layer. Split the data (you can use the log. reg. data or any other one) and train your network with 80% of the data. Test your network with the test data. Report the evaluation metrics for varying number of layers in the network. Also evaluate one more activation function (ReLU/tanh) other than sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8caaa59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d229be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert targets to binary classification problem\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356b1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff567036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, weights, biases, activation):\n",
    "    Z1 = np.dot(X, weights[0]) + biases[0]\n",
    "    A1 = activation(Z1)\n",
    "    Z2 = np.dot(A1, weights[1]) + biases[1]\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d1d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y):\n",
    "    m = Y.shape[0]\n",
    "    cost = -(1/m) * np.sum(Y * np.log(A2) + (1-Y) * np.log(1-A2))\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35463050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, Z1, A1, Z2, A2, weights, activation):\n",
    "    m = X.shape[0]\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    \n",
    "    if activation == sigmoid:\n",
    "        dZ1 = np.dot(dZ2, weights[1].T) * A1 * (1 - A1)\n",
    "    elif activation == relu:\n",
    "        dZ1 = np.dot(weights[1].T, dZ2.T) * np.int64(A1 > 0)\n",
    "    \n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return [dW1, dW2], [db1, db2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e26cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test, num_hidden_layers=0,\n",
    "                        hidden_layer_size=10,\n",
    "                        learning_rate=0.01,\n",
    "                        num_iterations=10000,\n",
    "                        print_cost=False,\n",
    "                        activation=sigmoid):\n",
    "    \n",
    "    # Convert targets to binary classification problem\n",
    "    y_train = (y_train > 0).astype(int)\n",
    "    y_test = (y_test > 0).astype(int)\n",
    "\n",
    "    # Initialize network architecture\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "    hidden_layer_sizes = [hidden_layer_size] * num_hidden_layers\n",
    "    layer_sizes = [input_size] + hidden_layer_sizes + [output_size]\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    for i in range(len(layer_sizes)-1):\n",
    "        w_i = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * 0.01\n",
    "        b_i = np.zeros((1, layer_sizes[i+1]))\n",
    "        weights.append(w_i)\n",
    "        biases.append(b_i)\n",
    "\n",
    "    # Train network using gradient descent\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        Zs = []\n",
    "        As = []\n",
    "        \n",
    "        A_prev = X_train\n",
    "        \n",
    "        for j in range(len(layer_sizes)-2):\n",
    "            W_j = weights[j]\n",
    "            b_j = biases[j]\n",
    "            Z_j = np.dot(A_prev,W_j) + b_j\n",
    "            \n",
    "            if activation == sigmoid:\n",
    "                A_j = sigmoid(Z_j)\n",
    "            elif activation == relu:\n",
    "                A_j = relu(Z_j)\n",
    "            elif activation == tanh:\n",
    "                A_j = tanh(Z_j)\n",
    "            \n",
    "            Zs.append(Z_j)\n",
    "            As.append(A_j)\n",
    "            \n",
    "            A_prev = A_j\n",
    "        \n",
    "        W_last_layer_index = len(layer_sizes)-2\n",
    "        \n",
    "        W_last_layer = weights[W_last_layer_index]\n",
    "        b_last_layer = biases[W_last_layer_index]\n",
    "        \n",
    "        Z_last_layer = np.dot(A_prev, W_last_layer) + b_last_layer\n",
    "        A_last_layer = sigmoid(Z_last_layer)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(A_last_layer, y_train)\n",
    "        costs.append(cost)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # Print cost\n",
    "        if i % 1000 == 0 and print_cost:\n",
    "            print(f\"Cost after iteration {i}: {cost}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    _, _, _, A_test = forward_propagation(X_test, weights, biases, activation)\n",
    "    y_pred = (A_test > 0.5).astype(int)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1)\n",
    "    recall = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_test == 1)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    \n",
    "    return {\n",
    "        \"weights\": weights,\n",
    "        \"biases\": biases,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c280db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohit\\AppData\\Local\\Temp\\ipykernel_22092\\1802097155.py:80: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1 Score: nan\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 20.0\n",
      "Recall: 30.0\n",
      "F1 Score: 24.0\n",
      "Accuracy: 0.3333333333333333\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1 Score: nan\n",
      "Hidden Layers: 1, Activation: sigmoid\n",
      "Accuracy: {'weights': [array([[-0.01453912,  0.0091768 ,  0.00549071, -0.00110845, -0.00685835,\n",
      "         0.00855496,  0.00504963, -0.00154029,  0.00140594,  0.00039532],\n",
      "       [ 0.00287803, -0.00922575,  0.00218635, -0.00050692,  0.0177393 ,\n",
      "        -0.00392756, -0.00640955, -0.0190437 ,  0.00378115,  0.02187042],\n",
      "       [-0.00212676,  0.00409184, -0.01207853, -0.00210428, -0.0051991 ,\n",
      "         0.00431893, -0.02215979, -0.00820454,  0.00564126, -0.00489774],\n",
      "       [-0.00476246,  0.00046182, -0.00040207,  0.01181775,  0.00382744,\n",
      "         0.00962202,  0.00061638,  0.02187565,  0.00199143,  0.00474243]]), array([[ 0.0055687 ],\n",
      "       [ 0.00656888],\n",
      "       [ 0.00132318],\n",
      "       [-0.00859259],\n",
      "       [ 0.00204927],\n",
      "       [-0.00488822],\n",
      "       [ 0.00280444],\n",
      "       [-0.00467823],\n",
      "       [-0.00982133],\n",
      "       [-0.01810629]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.3333333333333333, 'precision': nan, 'recall': 0.0, 'f1_score': nan}, Precision: {'weights': [array([[-0.00264915,  0.00458096, -0.01448265, -0.0141403 ,  0.00740177,\n",
      "         0.01171951,  0.01050735, -0.00706647, -0.01189417, -0.01452886],\n",
      "       [-0.0069001 ,  0.00257376, -0.00874633, -0.00256752,  0.00080862,\n",
      "         0.01429501,  0.00046547,  0.006649  ,  0.01402875, -0.00061845],\n",
      "       [ 0.00940976,  0.00915581,  0.0100434 ,  0.00680882, -0.00207202,\n",
      "        -0.01136711, -0.02378375,  0.0012249 ,  0.03038171, -0.00203367],\n",
      "       [-0.01915188, -0.01279742, -0.01705178, -0.02244042,  0.00185976,\n",
      "        -0.00312433,  0.00343292,  0.00688666, -0.00779293, -0.00942332]]), array([[-0.0127328 ],\n",
      "       [ 0.00519622],\n",
      "       [ 0.00780813],\n",
      "       [ 0.00442839],\n",
      "       [ 0.00555068],\n",
      "       [-0.01039928],\n",
      "       [ 0.01193242],\n",
      "       [ 0.01563461],\n",
      "       [-0.01126394],\n",
      "       [-0.00146726]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.6666666666666666, 'precision': 20.0, 'recall': 30.0, 'f1_score': 24.0}, Recall: {'weights': [array([[-0.00740971,  0.00226009, -0.00532388, -0.00761788,  0.00423764,\n",
      "        -0.00647235, -0.00775152, -0.00821358,  0.00498164, -0.00849068],\n",
      "       [-0.00238359,  0.00943562, -0.00465467, -0.00845447, -0.0185357 ,\n",
      "        -0.00287367, -0.00213087,  0.01323374, -0.00667042, -0.00172993],\n",
      "       [-0.00788343,  0.0051258 ,  0.01262803,  0.00050371,  0.0134563 ,\n",
      "        -0.00380113, -0.00180302, -0.00928529,  0.00050137,  0.00275603],\n",
      "       [-0.02198224,  0.00092496, -0.01377184, -0.00293338,  0.00044283,\n",
      "         0.01054669, -0.00475354,  0.01476058,  0.0047315 ,  0.00823309]]), array([[ 0.01359383],\n",
      "       [-0.0075717 ],\n",
      "       [-0.01234298],\n",
      "       [ 0.0069109 ],\n",
      "       [-0.00672536],\n",
      "       [-0.00714691],\n",
      "       [-0.00652019],\n",
      "       [-0.01826214],\n",
      "       [-0.0133004 ],\n",
      "       [ 0.01054873]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.3333333333333333, 'precision': nan, 'recall': 0.0, 'f1_score': nan}\n",
      "Accuracy: 0.45555555555555555\n",
      "Precision: 20.0\n",
      "Recall: 11.0\n",
      "F1 Score: 14.193548387096774\n",
      "Accuracy: 0.3333333333333333\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1 Score: nan\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 20.0\n",
      "Recall: 30.0\n",
      "F1 Score: 24.0\n",
      "Hidden Layers: 1, Activation: relu\n",
      "Accuracy: {'weights': [array([[-2.71500447e-02, -6.04884892e-03, -6.62660557e-03,\n",
      "         1.09351820e-02,  1.53705102e-02,  3.24624435e-03,\n",
      "        -1.09422165e-02, -1.04995667e-02,  2.36597076e-02,\n",
      "        -6.82640541e-03],\n",
      "       [-9.38703086e-03,  9.38801080e-03,  3.49721295e-03,\n",
      "        -1.56205938e-02, -7.36517802e-03,  1.61226615e-03,\n",
      "         9.76688163e-03,  1.50041602e-02,  5.02099441e-05,\n",
      "        -1.81199639e-03],\n",
      "       [ 7.79678434e-03, -4.93040489e-03, -1.96090758e-03,\n",
      "        -2.46200762e-03, -1.38596711e-03,  6.02385190e-03,\n",
      "        -5.15405265e-04,  1.14648812e-03, -2.72610971e-03,\n",
      "         8.61444393e-04],\n",
      "       [ 7.93175410e-04, -1.46652610e-02,  3.71289312e-03,\n",
      "        -2.02673576e-03, -1.19186718e-02, -9.09234666e-03,\n",
      "         5.12145296e-03,  2.06650623e-03,  9.85062502e-03,\n",
      "        -8.55542918e-04]]), array([[ 0.00816025],\n",
      "       [-0.00987963],\n",
      "       [ 0.01270818],\n",
      "       [-0.00827617],\n",
      "       [-0.01543442],\n",
      "       [-0.0166978 ],\n",
      "       [ 0.00249962],\n",
      "       [ 0.01274953],\n",
      "       [ 0.00943021],\n",
      "       [-0.01579427]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.45555555555555555, 'precision': 20.0, 'recall': 11.0, 'f1_score': 14.193548387096774}, Precision: {'weights': [array([[ 0.00953221,  0.00580286,  0.00597093, -0.00593597,  0.00063371,\n",
      "         0.00611468,  0.01591202, -0.00632309,  0.00203523, -0.01323711],\n",
      "       [-0.00859172,  0.0115216 , -0.00072918,  0.00352101,  0.01153764,\n",
      "         0.00455363,  0.00916155,  0.00475111, -0.01572037,  0.00066006],\n",
      "       [ 0.00694216, -0.00965219,  0.00113914, -0.00072923,  0.00434116,\n",
      "        -0.01332251,  0.0107437 ,  0.01343418,  0.00394563, -0.00640307],\n",
      "       [-0.01417911,  0.00390855, -0.02188897,  0.00799053,  0.00177704,\n",
      "        -0.01467292,  0.005836  ,  0.0047664 , -0.00439473, -0.00385921]]), array([[-0.00688252],\n",
      "       [ 0.00343752],\n",
      "       [ 0.00196868],\n",
      "       [ 0.00125494],\n",
      "       [-0.01988526],\n",
      "       [ 0.01685738],\n",
      "       [-0.02357861],\n",
      "       [-0.00238448],\n",
      "       [-0.00632477],\n",
      "       [-0.01082044]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.3333333333333333, 'precision': nan, 'recall': 0.0, 'f1_score': nan}, Recall: {'weights': [array([[ 6.74202622e-03,  6.78944482e-03,  2.29538831e-02,\n",
      "         1.59122581e-02, -1.66128130e-03, -1.31037006e-02,\n",
      "        -6.11342695e-03,  3.13385235e-03,  2.82007385e-03,\n",
      "        -2.37044784e-03],\n",
      "       [-2.99573912e-03, -1.34094191e-02,  1.52689746e-04,\n",
      "        -2.37279307e-02, -4.91848253e-03, -9.08580296e-03,\n",
      "         1.91088058e-02,  4.79223369e-03,  2.35350679e-03,\n",
      "        -7.97759528e-03],\n",
      "       [ 9.78316739e-03,  3.36679448e-03, -7.59694885e-03,\n",
      "        -1.07632776e-02,  1.61219197e-02, -1.48363950e-02,\n",
      "         6.00762350e-03,  1.31146009e-02,  7.49203887e-05,\n",
      "        -1.07651053e-02],\n",
      "       [ 1.53068810e-03, -6.74405325e-03, -8.60035072e-03,\n",
      "        -1.89415398e-02,  1.88481418e-02, -4.55546570e-03,\n",
      "         7.34756231e-03, -5.15252205e-03, -5.78491862e-03,\n",
      "        -9.02994664e-03]]), array([[ 0.01523076],\n",
      "       [ 0.00410968],\n",
      "       [-0.00710978],\n",
      "       [ 0.01166568],\n",
      "       [-0.003852  ],\n",
      "       [-0.00395038],\n",
      "       [-0.00240406],\n",
      "       [ 0.01347349],\n",
      "       [ 0.00687329],\n",
      "       [-0.01184145]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.6666666666666666, 'precision': 20.0, 'recall': 30.0, 'f1_score': 24.0}\n",
      "Accuracy: 0.3333333333333333\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1 Score: nan\n",
      "Accuracy: 0.3333333333333333\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1 Score: nan\n",
      "Accuracy: 0.5666666666666667\n",
      "Precision: 20.0\n",
      "Recall: 21.0\n",
      "F1 Score: 20.48780487804878\n",
      "Hidden Layers: 1, Activation: tanh\n",
      "Accuracy: {'weights': [array([[-1.66464699e-02,  8.27546077e-03,  1.38011982e-02,\n",
      "        -9.94032168e-03,  6.96353610e-04, -4.37456122e-03,\n",
      "         9.82438579e-03, -7.42215346e-03, -9.49459672e-03,\n",
      "         4.11033483e-03],\n",
      "       [ 9.68278362e-03, -1.31398800e-02,  9.67498495e-03,\n",
      "         8.75730893e-03,  1.62351191e-04, -9.03674925e-04,\n",
      "         4.83809344e-03,  2.13049313e-03,  5.64463618e-03,\n",
      "        -5.84332198e-03],\n",
      "       [ 1.15447197e-02,  5.29998821e-04, -2.07061539e-03,\n",
      "         1.59772457e-02,  1.08863694e-02, -9.24941749e-05,\n",
      "        -1.30457532e-02, -4.64193607e-03,  9.60937744e-03,\n",
      "         6.46520333e-03],\n",
      "       [-1.54672405e-03, -9.72310289e-03, -4.32453414e-03,\n",
      "        -3.50927562e-03, -1.29694230e-02,  1.32620354e-03,\n",
      "         1.97711626e-02, -2.27000597e-03, -1.83872689e-02,\n",
      "        -9.33123214e-03]]), array([[-0.01020439],\n",
      "       [-0.00248545],\n",
      "       [ 0.00538859],\n",
      "       [ 0.01402218],\n",
      "       [-0.00342626],\n",
      "       [ 0.0011805 ],\n",
      "       [-0.01196454],\n",
      "       [ 0.02466987],\n",
      "       [ 0.0112139 ],\n",
      "       [ 0.0062889 ]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.3333333333333333, 'precision': nan, 'recall': 0.0, 'f1_score': nan}, Precision: {'weights': [array([[-0.00964314, -0.00469572,  0.0063671 , -0.00754118,  0.00563209,\n",
      "        -0.00938914, -0.00931995, -0.00187582,  0.01859236, -0.00073776],\n",
      "       [ 0.01698581, -0.00937947, -0.00298548,  0.0123216 ,  0.00230056,\n",
      "        -0.00243013, -0.00682909,  0.01608795,  0.00620737, -0.00172074],\n",
      "       [-0.0080203 , -0.00853413, -0.00359173, -0.00807143,  0.00343032,\n",
      "        -0.00095828, -0.00878813,  0.01807709,  0.00478972, -0.00680713],\n",
      "       [-0.00663936, -0.00200201, -0.00386376, -0.00789473, -0.00984123,\n",
      "         0.00211638, -0.02654382, -0.01165368,  0.01278208,  0.02012453]]), array([[-8.92676447e-03],\n",
      "       [-9.47281058e-03],\n",
      "       [-9.15851467e-03],\n",
      "       [-1.26084767e-02],\n",
      "       [-5.36440103e-05],\n",
      "       [-1.60747273e-04],\n",
      "       [-1.24828198e-04],\n",
      "       [-3.67820819e-03],\n",
      "       [-1.40098940e-02],\n",
      "       [ 1.02222507e-03]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.3333333333333333, 'precision': nan, 'recall': 0.0, 'f1_score': nan}, Recall: {'weights': [array([[ 0.00132971,  0.01313142,  0.01380363, -0.01138996,  0.00394504,\n",
      "         0.00531107, -0.00823442, -0.00444855,  0.00764464,  0.01256797],\n",
      "       [-0.00602438,  0.00516217,  0.00349729, -0.01300689,  0.00264449,\n",
      "         0.00816723, -0.00506478,  0.02528389, -0.00641951, -0.00524448],\n",
      "       [ 0.00937719, -0.00614212,  0.00081843, -0.00284887, -0.0039944 ,\n",
      "        -0.00831358, -0.00812986, -0.02151112, -0.002348  ,  0.00909538],\n",
      "       [ 0.02178037,  0.00252097,  0.00673893,  0.00322379, -0.00451043,\n",
      "        -0.00668895,  0.00598953, -0.0031639 ,  0.00641494, -0.008163  ]]), array([[-0.00426514],\n",
      "       [ 0.00304924],\n",
      "       [-0.00418675],\n",
      "       [-0.00923894],\n",
      "       [-0.0054828 ],\n",
      "       [ 0.01613766],\n",
      "       [-0.00180795],\n",
      "       [-0.00595265],\n",
      "       [-0.03173336],\n",
      "       [-0.00141564]])], 'biases': [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0.]])], 'accuracy': 0.5666666666666667, 'precision': 20.0, 'recall': 21.0, 'f1_score': 20.48780487804878}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohit\\AppData\\Local\\Temp\\ipykernel_22092\\1802097155.py:79: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  accuracy = np.mean(y_pred == y_test)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (30,10) (30,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22092\\3533776469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_hidden_layers_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactivation_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Hidden Layers: {num_hidden_layers}, Activation: {activation.__name__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22092\\1802097155.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(X_train, X_test, y_train, y_test, num_hidden_layers, hidden_layer_size, learning_rate, num_iterations, print_cost, activation)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# Compute evaluation metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (30,10) (30,) "
     ]
    }
   ],
   "source": [
    "num_hidden_layers_list = [1, 2, 3]\n",
    "activation_list = [sigmoid, relu, tanh]\n",
    "\n",
    "for num_hidden_layers in num_hidden_layers_list:\n",
    "    for activation in activation_list:\n",
    "        accuracy, precision, recall = train_and_evaluate(X_train, X_test, y_train, y_test, num_hidden_layers=num_hidden_layers, activation=activation) , train_and_evaluate(X_train, X_test, y_train, y_test, num_hidden_layers=num_hidden_layers, activation=activation), train_and_evaluate(X_train, X_test, y_train, y_test, num_hidden_layers=num_hidden_layers, activation=activation)\n",
    "        print(f\"Hidden Layers: {num_hidden_layers}, Activation: {activation.__name__}\")\n",
    "        print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
